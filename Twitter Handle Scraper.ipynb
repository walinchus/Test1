{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting handler\n",
      "  Downloading https://files.pythonhosted.org/packages/64/27/8f2cfca6dc947f13455296b591b802904894a86873ccf7fc04048ea91bcb/handler-1.3.0.zip\n",
      "Building wheels for collected packages: handler\n",
      "  Running setup.py bdist_wheel for handler ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/Lucia/Library/Caches/pip/wheels/17/3c/36/789c95c290a96f751a9ca50c654765dffebd5e37fc7188c72a\n",
      "Successfully built handler\n",
      "Installing collected packages: handler\n",
      "Successfully installed handler-1.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install handler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HandlerItem(scrapy.Item):\n",
    "        # define the fields for your item here like:\n",
    "        # name = scrapy.Field()\n",
    "        link = scrapy.Field() # urls from the start page\n",
    "        link2 = scrapy.Field() # urls from secondary pages\n",
    "        domainlink = scrapy.Field() # domain links from the first page, for scraping\n",
    "        twitterlink = scrapy.Field() # twitter links from the first page\n",
    "        twitterlink2 = scrapy.Field() # twitter links from the secondary pages\n",
    "        twitterlinku = scrapy.Field() # cumulative list of twitter links\n",
    "        handles = scrapy.Field() # twitter links truncated into handles\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'handler.item'; 'handler' is not a package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-8f1d10f586e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# -*- coding: utf-8 -*-\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhandler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mhandler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHandlerItem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'handler.item'; 'handler' is not a package"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import handler\n",
    "from handler.item import HandlerItem\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain = 'twitter.com'\n",
    "start = 'http://twitter.com'\n",
    "\n",
    "class HouseSpider(scrapy.Spider):\n",
    "    name = 'handler'\n",
    "    allowed_domains = [domain]\n",
    "    start_urls = [start]\n",
    "\n",
    "    def parse(self, response):\n",
    "        item = HandlerItem()\n",
    "        item['link'] = []\n",
    "        item['link2'] = []\n",
    "        item['domainlink'] = []\n",
    "        item['domainlink2'] = []\n",
    "        item['twitterlink'] = []\n",
    "        item['twitterlink2'] = []\n",
    "        item['twitterlinku'] = []\n",
    "        item['handles'] = []\n",
    "\n",
    "        item['link'] = response.xpath('//a/@href').extract()\n",
    "\n",
    "        item['twitterlink'] = [w for w in item['link'] if \"twitter.com\" in w]\n",
    "        item['domainlink'] = [w for w in item['link'] if domain in w]\n",
    "        for url in item['twitterlink']:\n",
    "            item['twitterlinku'].append(url)\n",
    "        for url in item['domainlink']:\n",
    "            request = scrapy.Request(url, callback=self.parse2)\n",
    "            request.meta['item'] = item\n",
    "            yield request\n",
    "\n",
    "        for link in item['twitterlinku']:\n",
    "            handle = link.split(\".com/\")[1]\n",
    "            if \"/\" in handle:\n",
    "                handle = handle.split(\"/\")[0]\n",
    "            item['handles'].append(handle)\n",
    "        yield item\n",
    "        print (item['handles'])\n",
    "\n",
    "    def parse2(self, response):\n",
    "        item = response.meta['item']\n",
    "        item['link2'] = response.xpath('//a/@href').extract()\n",
    "        item['twitterlink2'] = [w for w in item['link2'] if \"twitter.com\" in w]\n",
    "        for url in item['twitterlink2']:\n",
    "            item['twitterlinku'].append(url)\n",
    "            print (url)\n",
    "        yield item['twitterlinku']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
